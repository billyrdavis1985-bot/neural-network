# Neural Network from Scratch

A from-scratch implementation of a deep neural network in NumPy.

## Architecture
- Input: 2 features
- Hidden layers: 20 → 10 → 5 neurons (ReLU activation)
- Output: 1 neuron (Sigmoid for binary classification)

## Features
- Custom sigmoid and ReLU activations + derivatives
- Deep parameter initialization
- Linear forward pass implementation

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/billyrdavis1985-bot/neural-network/blob/main/neural_network_from_scratch.ipynb)

Work in progress — forward prop, backprop, training loop coming soon!
